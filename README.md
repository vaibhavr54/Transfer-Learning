# Transfer Learning Strategies Comparison

A comprehensive comparison of three transfer learning approaches using VGG16 for Dogs vs Cats binary image classification. This project demonstrates the effectiveness of different transfer learning strategies and their impact on model performance.

## ğŸ¯ Project Overview

This repository contains three Jupyter notebooks that showcase different transfer learning techniques:

1. **Feature Extraction with Data Augmentation** - Frozen VGG16 with image augmentation
2. **Feature Extraction Only** - Frozen VGG16 without augmentation
3. **Fine-tuning** - Partially unfrozen VGG16 with selective layer training

## ğŸ“Š Results Summary

| Approach | Training Accuracy | Validation Accuracy | Overfitting Level | Best For |
|----------|------------------|-------------------|------------------|----------|
| Feature Extraction + Augmentation | 92.9% | 91.5% | Moderate | Balanced performance |
| Feature Extraction Only | 98.3% | 90.8% | Severe | Quick prototyping |
| Fine-tuning | **99.9%** | **95.2%** | Mild | **Best performance** |

## ğŸ“ Repository Structure

```
â”œâ”€â”€ feature_extraction_augmentation.ipynb    # Feature extraction with data augmentation
â”œâ”€â”€ feature_extraction_only.ipynb           # Feature extraction without augmentation
â”œâ”€â”€ fine_tuning.ipynb                       # Fine-tuning approach
â””â”€â”€ README.md                                          
```

## ğŸš€ Key Findings

### 1. **Data Augmentation is Critical**
- **With augmentation**: Validation accuracy of 91.5% with controlled overfitting
- **Without augmentation**: Severe overfitting with validation accuracy dropping to 90.8%
- **Impact**: Data augmentation improves generalization significantly

### 2. **Fine-tuning Delivers Best Results**
- Achieved **95.2% validation accuracy** - highest among all approaches
- Unfroze last convolutional block (block5) of VGG16
- Used low learning rate (1e-5) to preserve pre-trained features

### 3. **Progressive Learning Strategy**
- Start with frozen features + augmentation for stable baseline
- Apply fine-tuning for performance boost
- Avoid training without augmentation to prevent overfitting

## ğŸ“ˆ Detailed Performance Analysis

### Notebook 1: Feature Extraction + Data Augmentation
- **Architecture**: VGG16 (frozen) â†’ Flatten â†’ Dense(256) â†’ Dense(1, sigmoid)
- **Training Progress**: 86.5% â†’ 92.9% training accuracy
- **Validation Stability**: 90.9% â†’ 91.5% with plateau around epoch 3-4
- **Outcome**: Best balance between performance and overfitting control

### Notebook 2: Feature Extraction Only
- **Same Architecture** as Notebook 1 but without data augmentation
- **Rapid Overfitting**: Training accuracy jumps to 98.3% while validation peaks early
- **Validation Decline**: Drops from 91.5% to 90.8% showing poor generalization
- **Lesson**: Demonstrates why data augmentation is essential

### Notebook 3: Fine-tuning
- **Modified Architecture**: Unfroze VGG16's block5 layers for adaptive learning
- **Optimizer**: RMSprop with very low learning rate (1e-5)
- **Superior Results**: 99.9% training, 95.2% validation accuracy
- **Best Practice**: Selective unfreezing with careful learning rate tuning

## ğŸ› ï¸ Technical Implementation

### Base Model
- **Pre-trained Network**: VGG16 trained on ImageNet
- **Input Shape**: 150x150x3 RGB images
- **Dataset**: Dogs vs Cats (20,000 training, 5,000 validation images)

### Data Augmentation Techniques
```
rotation_range=40,
width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.2,
zoom_range=0.2,
horizontal_flip=True,
fill_mode='nearest'
```

### Training Configuration
- **Epochs**: 10 for all approaches
- **Batch Size**: 32
- **Loss Function**: Binary crossentropy
- **Metrics**: Accuracy

## ğŸ“‹ Requirements

```
tensorflow>=2.8.0
keras>=2.8.0
numpy>=1.21.0
matplotlib>=3.5.0
pillow>=8.0.0
jupyter>=1.0.0
```

## ğŸš€ Getting Started

1. **Clone the repository**
   ```
   git clone https://github.com/vaibhavr54/Transfer-Learning.git
   cd Transfer-Learning
   ```

2. **Download the dataset**
   - Get the Dogs vs Cats dataset from [Kaggle](https://www.kaggle.com/c/dogs-vs-cats/data)
   - Extract and organize in the following structure:
   ```
   data/
   â”œâ”€â”€ train/
   â”‚   â”œâ”€â”€ dogs/
   â”‚   â””â”€â”€ cats/
   â””â”€â”€ validation/
       â”œâ”€â”€ dogs/
       â””â”€â”€ cats/
   ```

3. **Run the notebooks**
   - Open notebooks in Google Colab or Jupyter
   - Upload your dataset to the appropriate location
   - Run cells sequentially to reproduce results

## ğŸ“ Learning Outcomes

This project demonstrates:
- **Transfer Learning Fundamentals**: How to leverage pre-trained models
- **Data Augmentation Impact**: Critical role in preventing overfitting
- **Fine-tuning Strategy**: When and how to unfreeze layers selectively
- **Performance Comparison**: Systematic evaluation of different approaches
- **Best Practices**: Learning rate selection, layer freezing, and optimization

## ğŸ” Key Insights

1. **Start Simple**: Begin with frozen features and data augmentation
2. **Monitor Overfitting**: Watch training vs validation accuracy gaps
3. **Fine-tune Carefully**: Use low learning rates when unfreezing layers
4. **Data Augmentation**: Always include when working with limited datasets
5. **Progressive Approach**: Build complexity incrementally

## ğŸ“Š Visual Results

Each notebook includes:
- Training/validation accuracy plots
- Loss function progression
- Sample predictions with confidence scores
- Confusion matrices for detailed analysis

## ğŸ¤ Contributing

Feel free to fork this repository and experiment with:
- Different pre-trained models (ResNet, InceptionV3, etc.)
- Alternative data augmentation strategies
- Various fine-tuning approaches
- Different datasets for transfer learning

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ“§ Contact

For questions or suggestions, please open an issue or feel free to reach out.

---

â­ **If you found this project helpful, please give it a star!** â­
